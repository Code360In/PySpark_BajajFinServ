{"cells":[{"cell_type":"markdown","source":["## 02-pyspark-rdd-to-dataframe.py"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"65f30515-62f2-4da0-b774-998f77c9d3ff","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# 02-pyspark-rdd-to-dataframe.py\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('PySparkExamples').getOrCreate()\n\ndept = [(\"Finance\", 10), (\"Marketing\", 20), (\"Sales\", 30), (\"IT\", 40)]\nrdd = spark.sparkContext.parallelize(dept)\ndf = rdd.toDF()\nprint(\"DataFrame columns are:\", df.columns, \"with column count:\", len(df.columns), \"and with row count:\", df.count())\ndf.printSchema()\ndf.show()\ndf.show(truncate = True)\ndf.show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b38f8cfc-05ac-464b-a296-222efbdca5cf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"DataFrame columns are: ['_1', '_2'] with column count: 2 and with row count: 4\nroot\n |-- _1: string (nullable = true)\n |-- _2: long (nullable = true)\n\n+---------+---+\n|       _1| _2|\n+---------+---+\n|  Finance| 10|\n|Marketing| 20|\n|    Sales| 30|\n|       IT| 40|\n+---------+---+\n\n+---------+---+\n|       _1| _2|\n+---------+---+\n|  Finance| 10|\n|Marketing| 20|\n|    Sales| 30|\n|       IT| 40|\n+---------+---+\n\n+---------+---+\n|_1       |_2 |\n+---------+---+\n|Finance  |10 |\n|Marketing|20 |\n|Sales    |30 |\n|IT       |40 |\n+---------+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["DataFrame columns are: ['_1', '_2'] with column count: 2 and with row count: 4\nroot\n |-- _1: string (nullable = true)\n |-- _2: long (nullable = true)\n\n+---------+---+\n|       _1| _2|\n+---------+---+\n|  Finance| 10|\n|Marketing| 20|\n|    Sales| 30|\n|       IT| 40|\n+---------+---+\n\n+---------+---+\n|       _1| _2|\n+---------+---+\n|  Finance| 10|\n|Marketing| 20|\n|    Sales| 30|\n|       IT| 40|\n+---------+---+\n\n+---------+---+\n|_1       |_2 |\n+---------+---+\n|Finance  |10 |\n|Marketing|20 |\n|Sales    |30 |\n|IT       |40 |\n+---------+---+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["deptColumns = ['Department_Name', 'Department_ID']\ndf2 = rdd.toDF(deptColumns)\nprint(\"DataFrame columns are:\", df2.columns, \"with column count:\", len(df2.columns), \"and with row count:\", df2.count())\ndf2.printSchema()\ndf2.show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"284072e2-7003-417c-bb86-6b22324b682d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"DataFrame columns are: ['Department_Name', 'Department_ID'] with column count: 2 and with row count: 4\nroot\n |-- Department_Name: string (nullable = true)\n |-- Department_ID: long (nullable = true)\n\n+---------------+-------------+\n|Department_Name|Department_ID|\n+---------------+-------------+\n|Finance        |10           |\n|Marketing      |20           |\n|Sales          |30           |\n|IT             |40           |\n+---------------+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["DataFrame columns are: ['Department_Name', 'Department_ID'] with column count: 2 and with row count: 4\nroot\n |-- Department_Name: string (nullable = true)\n |-- Department_ID: long (nullable = true)\n\n+---------------+-------------+\n|Department_Name|Department_ID|\n+---------------+-------------+\n|Finance        |10           |\n|Marketing      |20           |\n|Sales          |30           |\n|IT             |40           |\n+---------------+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["deptDF = spark.createDataFrame(data = dept, schema = deptColumns)\ndeptDF.printSchema()\ndeptDF.show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ba4b4f9d-d549-4227-bcf2-ddb300c27303","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Department_Name: string (nullable = true)\n |-- Department_ID: long (nullable = true)\n\n+---------------+-------------+\n|Department_Name|Department_ID|\n+---------------+-------------+\n|Finance        |10           |\n|Marketing      |20           |\n|Sales          |30           |\n|IT             |40           |\n+---------------+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Department_Name: string (nullable = true)\n |-- Department_ID: long (nullable = true)\n\n+---------------+-------------+\n|Department_Name|Department_ID|\n+---------------+-------------+\n|Finance        |10           |\n|Marketing      |20           |\n|Sales          |30           |\n|IT             |40           |\n+---------------+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType\ndeptSchema = StructType([       \n    StructField('dept_name', StringType(), True),\n    StructField('dept_id', StringType(), True)])\n\ndeptDF1 = spark.createDataFrame(data = dept, schema = deptSchema)\ndeptDF1.printSchema()\ndeptDF1.show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d74b1018-95b9-4c86-8a28-b63333e30586","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- dept_name: string (nullable = true)\n |-- dept_id: string (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- dept_name: string (nullable = true)\n |-- dept_id: string (nullable = true)\n\n+---------+-------+\n|dept_name|dept_id|\n+---------+-------+\n|Finance  |10     |\n|Marketing|20     |\n|Sales    |30     |\n|IT       |40     |\n+---------+-------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"02-pyspark-rdd-to-dataframe.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3372251589934818}},"nbformat":4,"nbformat_minor":0}
