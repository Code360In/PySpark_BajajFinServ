{"cells":[{"cell_type":"markdown","source":["### Testing with PySpark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"992733a6-a730-458c-b20e-a141f9d992af","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[1]\").appName(\"PySparkExamples\").getOrCreate()\n# Here local[1] means how many cores local executor will consume, here it is 1\n# Use local[x] when running in standalone mode. x should be an integer value and should be\n# greater than 0; this representes how many partitions it should create when using RDD (Resilient\n# Distributed Dataset)\n\ndata = [('Amal', 'Das', 'India', 'West Bengal'),\n        ('Kamal', 'Singh', 'India', 'Tamilnadu'),\n        ('Rabi', 'Narayan', 'India', 'Gujrat'),\n        ('Maria', 'Johns', 'India', 'Karnataka')]\ncolumns = [\"FirstName\", \"LastName\", \"Country\", \"State\"]\ndf = spark.createDataFrame(data = data, schema = columns)\ndf.show()\nprint (df.collect(), \"\\n\")\nprint (df.schema)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"77f4f9e6-d72a-4dc1-bd49-86d29dec3e9e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+--------+-------+-----------+\n|FirstName|LastName|Country|      State|\n+---------+--------+-------+-----------+\n|     Amal|     Das|  India|West Bengal|\n|    Kamal|   Singh|  India|  Tamilnadu|\n|     Rabi| Narayan|  India|     Gujrat|\n|    Maria|   Johns|  India|  Karnataka|\n+---------+--------+-------+-----------+\n\n[Row(FirstName='Amal', LastName='Das', Country='India', State='West Bengal'), Row(FirstName='Kamal', LastName='Singh', Country='India', State='Tamilnadu'), Row(FirstName='Rabi', LastName='Narayan', Country='India', State='Gujrat'), Row(FirstName='Maria', LastName='Johns', Country='India', State='Karnataka')] \n\nStructType([StructField('FirstName', StringType(), True), StructField('LastName', StringType(), True), StructField('Country', StringType(), True), StructField('State', StringType(), True)])\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+--------+-------+-----------+\n|FirstName|LastName|Country|      State|\n+---------+--------+-------+-----------+\n|     Amal|     Das|  India|West Bengal|\n|    Kamal|   Singh|  India|  Tamilnadu|\n|     Rabi| Narayan|  India|     Gujrat|\n|    Maria|   Johns|  India|  Karnataka|\n+---------+--------+-------+-----------+\n\n[Row(FirstName='Amal', LastName='Das', Country='India', State='West Bengal'), Row(FirstName='Kamal', LastName='Singh', Country='India', State='Tamilnadu'), Row(FirstName='Rabi', LastName='Narayan', Country='India', State='Gujrat'), Row(FirstName='Maria', LastName='Johns', Country='India', State='Karnataka')] \n\nStructType([StructField('FirstName', StringType(), True), StructField('LastName', StringType(), True), StructField('Country', StringType(), True), StructField('State', StringType(), True)])\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"FirstProg","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1171087659855596}},"nbformat":4,"nbformat_minor":0}
